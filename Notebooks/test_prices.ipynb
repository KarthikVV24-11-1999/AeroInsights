{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2039ad3-faa0-4f49-877f-cd250001f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7256a770-34a6-4d59-89a4-9cbdc46dab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594e1c9b-67dd-4f58-909b-12c7a2c9e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Preprocess\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"75g\") \\\n",
    "    .config(\"spark.pyspark.python\", \"/usr/local/bin/python3.9\") \\\n",
    "    .config(\"spark.pyspark.driver.python\", \"/usr/local/bin/python3.9\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read CSV into DataFrame\n",
    "# prices = spark.read.csv(\"itineraries.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e8fbeb-36c2-4046-a492-87d53621b61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight_prices = spark.read.csv(\"itineraries.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d484ad-9101-42a9-8fa3-8b7d643853ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_prices_3 = flight_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ba21fc1-1f79-4703-9f22-7f6f134861be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def duration_to_minutes_2(duration_str):\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_l = parts[0].split('P')\n",
    "        days = int(parts_l[1][0])\n",
    "    except:\n",
    "        days = 0\n",
    "\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_r = parts[1].split('H')\n",
    "        hours = int(parts_r[0]) if len(parts_r) > 1 else 0\n",
    "    except:\n",
    "        hours = 0\n",
    "\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_r = parts[1].split('H')\n",
    "        minutes = int(parts_r[-1][:-1])\n",
    "    except:\n",
    "        minutes = 0\n",
    "\n",
    "    try:\n",
    "        return ((24*days) + hours) * 60 + minutes\n",
    "    except:\n",
    "        return \"error\"\n",
    "    # try:\n",
    "    #     parts = duration_str.split('T')\n",
    "    #     parts_l = parts[0].split('P')\n",
    "    #     days = int(parts_l[1][0])\n",
    "    #     parts_r = parts[1].split('H')\n",
    "    #     hours = int(parts_r[0]) if len(parts_r) > 1 else 0\n",
    "    #     minutes = int(parts_r[-1][:-1])\n",
    "    #     return ((24*days) + hours) * 60 + minutes\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1ac4e1c7-9ef0-4f65-ba4b-c0142499e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(duration_to_minutes_2(\"PT5H\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05c555-350b-4b9b-8d57-358194792f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "796cbbbf-a225-4c8c-809d-5d47351daef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF (User Defined Function) to convert duration strings to minutes\n",
    "def duration_to_minutes(duration_str):\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_l = parts[0].split('P')\n",
    "        days = int(parts_l[1][0])\n",
    "    except:\n",
    "        days = 0\n",
    "\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_r = parts[1].split('H')\n",
    "        hours = int(parts_r[0]) if len(parts_r) > 1 else 0\n",
    "    except:\n",
    "        hours = 0\n",
    "\n",
    "    try:\n",
    "        parts = duration_str.split('T')\n",
    "        parts_r = parts[1].split('H')\n",
    "        minutes = int(parts_r[-1][:-1])\n",
    "    except:\n",
    "        minutes = 0\n",
    "\n",
    "    try:\n",
    "        return ((24*days) + hours) * 60 + minutes\n",
    "    except:\n",
    "        return 0                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d1b8980-e9ee-4d6a-9498-233a0360e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "duration_to_minutes_udf = udf(duration_to_minutes, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8a540498-aef5-43a4-bba5-32e8100d2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_prices_2 = flight_prices.withColumn(\n",
    "    \"travelDurationMinutes\",\n",
    "    duration_to_minutes_udf(\"travelDuration\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e91cc242-b386-42aa-a359-50a3d98c9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "a = flight_prices_2.filter(col(\"travelDurationMinutes\")==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "140c00ea-8b73-4ba8-a5c5-898e92e79ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f910006c-37ee-4007-9b69-8bcf24d6c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>...</th>\n",
       "      <th>segmentsArrivalTimeRaw</th>\n",
       "      <th>segmentsArrivalAirportCode</th>\n",
       "      <th>segmentsDepartureAirportCode</th>\n",
       "      <th>segmentsAirlineName</th>\n",
       "      <th>segmentsAirlineCode</th>\n",
       "      <th>segmentsEquipmentDescription</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>segmentsDistance</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "      <th>travelDurationMinutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [legId, searchDate, flightDate, startingAirport, destinationAirport, fareBasisCode, travelDuration, elapsedDays, isBasicEconomy, isRefundable, isNonStop, baseFare, totalFare, seatsRemaining, totalTravelDistance, segmentsDepartureTimeEpochSeconds, segmentsDepartureTimeRaw, segmentsArrivalTimeEpochSeconds, segmentsArrivalTimeRaw, segmentsArrivalAirportCode, segmentsDepartureAirportCode, segmentsAirlineName, segmentsAirlineCode, segmentsEquipmentDescription, segmentsDurationInSeconds, segmentsDistance, segmentsCabinCode, travelDurationMinutes]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 28 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948df935-9a3b-462f-8aee-4a29f6a07a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_prices.limit(1).toPandas().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "397c143d-4f30-4951-9297-a6df5697e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+--------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+---------------------+\n",
      "|               legId|searchDate|flightDate|startingAirport|destinationAirport|fareBasisCode|travelDuration|elapsedDays|isBasicEconomy|isRefundable|isNonStop|baseFare|totalFare|seatsRemaining|totalTravelDistance|segmentsDepartureTimeEpochSeconds|segmentsDepartureTimeRaw|segmentsArrivalTimeEpochSeconds|segmentsArrivalTimeRaw|segmentsArrivalAirportCode|segmentsDepartureAirportCode| segmentsAirlineName|segmentsAirlineCode|segmentsEquipmentDescription|segmentsDurationInSeconds|segmentsDistance|segmentsCabinCode|travelDurationMinutes|\n",
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+--------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+---------------------+\n",
      "|9ca0e81111c683bec...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H29M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650214620|    2022-04-17T12:57:...|                     1650223560|  2022-04-17T15:26:...|                       BOS|                         ATL|               Delta|                 DL|                 Airbus A321|                     8940|             947|            coach|                  149|\n",
      "|98685953630e772a0...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H30M|          0|         false|       false|     true|  217.67|    248.6|             4|                947|                       1650191400|    2022-04-17T06:30:...|                     1650200400|  2022-04-17T09:00:...|                       BOS|                         ATL|               Delta|                 DL|                 Airbus A321|                     9000|             947|            coach|                  150|\n",
      "|98d90cbc32bfbb05c...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H30M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650209700|    2022-04-17T11:35:...|                     1650218700|  2022-04-17T14:05:...|                       BOS|                         ATL|               Delta|                 DL|              Boeing 757-200|                     9000|             947|            coach|                  150|\n",
      "|969a269d38eae583f...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H32M|          0|         false|       false|     true|  217.67|    248.6|             8|                947|                       1650218340|    2022-04-17T13:59:...|                     1650227460|  2022-04-17T16:31:...|                       BOS|                         ATL|               Delta|                 DL|                 Airbus A321|                     9120|             947|            coach|                  152|\n",
      "|980370cf27c89b40d...|2022-04-16|2022-04-17|            ATL|               BOS|     LA0NX0MC|       PT2H34M|          0|         false|       false|     true|  217.67|    248.6|             9|                947|                       1650203940|    2022-04-17T09:59:...|                     1650213180|  2022-04-17T12:33:...|                       BOS|                         ATL|               Delta|                 DL|                 Airbus A321|                     9240|             947|            coach|                  154|\n",
      "|9335fae376c38bb61...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT4H12M|          0|         false|       false|    false|  213.02|    251.1|             3|                956|             1650198000||16502...|    2022-04-17T08:20:...|           1650203400||16502...|  2022-04-17T09:50:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A320||Airb...|               5400||7500|        228||728|     coach||coach|                  252|\n",
      "|3904bf87f2d1daf33...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT5H18M|          0|         false|       false|    false|  213.02|    251.1|             3|                956|             1650198000||16502...|    2022-04-17T08:20:...|           1650203400||16502...|  2022-04-17T09:50:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A320||Boei...|               5400||8280|        228||728|     coach||coach|                  318|\n",
      "|d93988734c44a3c07...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT5H32M|          0|         false|       false|    false|  213.02|    251.1|             7|                956|             1650193200||16502...|    2022-04-17T07:00:...|           1650198060||16502...|  2022-04-17T08:21:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A319||Airb...|               4860||7500|        228||728|     coach||coach|                  332|\n",
      "|562e7d5dd6ecbf150...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT6H38M|          0|         false|       false|    false|  213.02|    251.1|             7|                956|             1650193200||16502...|    2022-04-17T07:00:...|           1650198060||16502...|  2022-04-17T08:21:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A319||Boei...|               4860||8280|        228||728|     coach||coach|                  398|\n",
      "|c38a6e4b807d15541...|2022-04-16|2022-04-17|            ATL|               BOS|     VAA0AKEN|       PT4H46M|          0|         false|       false|    false|  213.02|    252.6|             1|                947|             1650187800||16501...|    2022-04-17T05:30:...|           1650194280||16502...|  2022-04-17T07:18:...|                  IAD||BOS|                    ATL||IAD|      United||United|             UA||UA|        Airbus A319||Boei...|               6480||5940|        541||406|     coach||coach|                  286|\n",
      "|f66d72ba3a5265766...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT5H45M|          0|         false|       false|    false|  213.02|    252.6|             3|               1462|             1650220740||16502...|    2022-04-17T14:39:...|           1650228840||16502...|  2022-04-17T15:54:...|                  ORD||BOS|                    ATL||ORD|American Airlines...|             AA||AA|        Embraer 175||Boei...|               8100||8340|        600||862|     coach||coach|                  345|\n",
      "|e7c4054e85cca9bc7...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT5H59M|          0|         false|       false|    false|  213.02|    252.6|             5|               1462|             1650232800||16502...|    2022-04-17T18:00:...|           1650240660||16502...|  2022-04-17T19:11:...|                  ORD||BOS|                    ATL||ORD|American Airlines...|             AA||AA|        Embraer 175||Boei...|               7860||8640|        600||862|     coach||coach|                  359|\n",
      "|5fa8c0f8b25eb24bf...|2022-04-16|2022-04-17|            ATL|               BOS|     V0AJZNN1|       PT7H18M|          0|         false|       false|    false|  213.02|    252.6|             3|               1462|             1650220740||16502...|    2022-04-17T14:39:...|           1650228840||16502...|  2022-04-17T15:54:...|                  ORD||BOS|                    ATL||ORD|American Airlines...|             AA||AA|        Embraer 175||Airb...|               8100||7920|        600||862|     coach||coach|                  438|\n",
      "|948d26b3e5658762c...|2022-04-16|2022-04-17|            ATL|               BOS|     VAA0AKEN|       PT8H10M|          0|         false|       false|    false|  213.02|    252.6|             2|               1462|             1650190200||16502...|    2022-04-17T06:10:...|           1650198000||16502...|  2022-04-17T07:20:...|                  ORD||BOS|                    ATL||ORD|      United||United|             UA||UA|        Embraer 175 (Enha...|               7800||8640|        600||862|     coach||coach|                  490|\n",
      "|eaf033a044596f0a7...|2022-04-16|2022-04-17|            ATL|               BOS|     L0AJZNN1|       PT4H17M|          0|         false|       false|    false|  260.47|   302.11|             1|                956|             1650233700||16502...|    2022-04-17T18:15:...|           1650238620||16502...|  2022-04-17T19:37:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Canadian Regional...|               4920||7620|        228||728|     coach||coach|                  257|\n",
      "|721d9a2f66fe479e7...|2022-04-16|2022-04-17|            ATL|               BOS|     L0AJZNN1|       PT4H36M|          0|         false|       false|    false|  260.47|   302.11|             1|                956|             1650207720||16502...|    2022-04-17T11:02:...|           1650212880||16502...|  2022-04-17T12:28:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Canadair Regional...|               5160||7860|        228||728|     coach||coach|                  276|\n",
      "|a9f012defb9227f69...|2022-04-16|2022-04-17|            ATL|               BOS|     L0AJZNN1|       PT4H45M|          0|         false|       false|    false|  260.47|   302.11|             1|                956|             1650226680||16502...|    2022-04-17T16:18:...|           1650230760||16502...|  2022-04-17T17:26:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A319||Boei...|               4080||7860|        228||728|     coach||coach|                  285|\n",
      "|676e25bb0ec021d33...|2022-04-16|2022-04-17|            ATL|               BOS|     L0AJZNN1|        PT6H2M|          0|         false|       false|    false|  260.47|   302.11|             1|                956|             1650207720||16502...|    2022-04-17T11:02:...|           1650212880||16502...|  2022-04-17T12:28:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Canadair Regional...|               5160||7740|        228||728|     coach||coach|                  362|\n",
      "|712a4b5789013e5a4...|2022-04-16|2022-04-17|            ATL|               BOS|     L0AJZNN1|       PT6H14M|          0|         false|       false|    false|  260.47|   302.11|             1|                956|             1650226680||16502...|    2022-04-17T16:18:...|           1650230760||16502...|  2022-04-17T17:26:...|                  CLT||BOS|                    ATL||CLT|American Airlines...|             AA||AA|        Airbus A319||Airb...|               4080||7620|        228||728|     coach||coach|                  374|\n",
      "|a6a69aee2e8f75f9b...|2022-04-16|2022-04-17|            ATL|               BOS|     WAA0AHBN|       PT9H46M|          1|          true|       false|    false|   258.6|    307.2|             9|                947|             1650244980||16502...|    2022-04-17T21:23:...|           1650253320||16502...|  2022-04-17T23:42:...|                  EWR||BOS|                    ATL||EWR|      United||United|             UA||UA|        Airbus A319||Airb...|               8340||4140|        762||185|     coach||coach|                  586|\n",
      "+--------------------+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+--------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_prices_2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0edf7950-8911-4701-b38c-535d988d776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legId',\n",
       " 'searchDate',\n",
       " 'flightDate',\n",
       " 'startingAirport',\n",
       " 'destinationAirport',\n",
       " 'fareBasisCode',\n",
       " 'travelDuration',\n",
       " 'elapsedDays',\n",
       " 'isBasicEconomy',\n",
       " 'isRefundable',\n",
       " 'isNonStop',\n",
       " 'baseFare',\n",
       " 'totalFare',\n",
       " 'seatsRemaining',\n",
       " 'totalTravelDistance',\n",
       " 'segmentsDepartureTimeEpochSeconds',\n",
       " 'segmentsDepartureTimeRaw',\n",
       " 'segmentsArrivalTimeEpochSeconds',\n",
       " 'segmentsArrivalTimeRaw',\n",
       " 'segmentsArrivalAirportCode',\n",
       " 'segmentsDepartureAirportCode',\n",
       " 'segmentsAirlineName',\n",
       " 'segmentsAirlineCode',\n",
       " 'segmentsEquipmentDescription',\n",
       " 'segmentsDurationInSeconds',\n",
       " 'segmentsDistance',\n",
       " 'segmentsCabinCode']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa5c005e-a244-455f-b426-4e85285d67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [\"startingAirport\",\"destinationAirport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0d46a161-8ace-481c-849f-49236f56d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.=>           (184 + 8) / 232]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[Stage 50:============================================>         (191 + 8) / 232]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39mindexers \u001b[38;5;241m+\u001b[39m encoders)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit the pipeline to the data and transform the DataFrame\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mfit(flight_prices)\n\u001b[1;32m     17\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(flight_prices)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Show the encoded DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/ml/pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     model \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mfit(dataset)\n\u001b[1;32m    135\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_java(dataset)\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mfit(dataset\u001b[38;5;241m.\u001b[39m_jdf)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:============================================>         (192 + 8) / 232]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"keep\") for column in ohe_cols]\n",
    "\n",
    "# Perform OneHotEncoding on the indexed columns\n",
    "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_onehot\") for column in ohe_cols]\n",
    "\n",
    "# Create a pipeline to execute the indexers and encoders sequentially\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "\n",
    "# Fit the pipeline to the data and transform the DataFrame\n",
    "model = pipeline.fit(flight_prices)\n",
    "encoded_df = model.transform(flight_prices)\n",
    "\n",
    "# Show the encoded DataFrame\n",
    "encoded_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4fd9a6be-e03f-40b7-b9f3-98c159a71ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/01 00:22:15 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/12/temp_shuffle_f8243f8e-d7c4-4efc-b499-6967cc8f1b6d\n",
      "24/05/01 00:22:15 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 192.0 in stage 50.0 (TID 3231)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:15 ERROR Executor: Exception in task 192.0 in stage 50.0 (TID 3231): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/12/temp_shuffle_f8243f8e-d7c4-4efc-b499-6967cc8f1b6d (No such file or directory)\n",
      "24/05/01 00:22:15 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/3b/temp_shuffle_e0d20a09-aa84-4f88-99e3-f3cdf73d7622\n",
      "24/05/01 00:22:15 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 194.0 in stage 50.0 (TID 3233)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:15 ERROR Executor: Exception in task 194.0 in stage 50.0 (TID 3233): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/3b/temp_shuffle_e0d20a09-aa84-4f88-99e3-f3cdf73d7622 (No such file or directory)\n",
      "24/05/01 00:22:15 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/05/temp_shuffle_638600a3-da15-4a36-a63d-876558b9906e\n",
      "24/05/01 00:22:15 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/10/temp_shuffle_6e7ce5e2-8ed7-478e-be15-88f6ed705faf\n",
      "24/05/01 00:22:15 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 193.0 in stage 50.0 (TID 3232)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:15 ERROR Executor: Exception in task 193.0 in stage 50.0 (TID 3232): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/10/temp_shuffle_6e7ce5e2-8ed7-478e-be15-88f6ed705faf (No such file or directory)\n",
      "24/05/01 00:22:15 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 196.0 in stage 50.0 (TID 3235)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:15 ERROR Executor: Exception in task 196.0 in stage 50.0 (TID 3235): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/05/temp_shuffle_638600a3-da15-4a36-a63d-876558b9906e (No such file or directory)\n",
      "24/05/01 00:22:15 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/29/temp_shuffle_73967d98-05fb-44c8-9337-77782c53d1dd\n",
      "24/05/01 00:22:15 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 195.0 in stage 50.0 (TID 3234)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:15 ERROR Executor: Exception in task 195.0 in stage 50.0 (TID 3234): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/29/temp_shuffle_73967d98-05fb-44c8-9337-77782c53d1dd (No such file or directory)\n",
      "24/05/01 00:22:16 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/02/temp_shuffle_facfe072-044f-44ff-8be2-bf8a7e511a7f\n",
      "24/05/01 00:22:16 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 197.0 in stage 50.0 (TID 3236)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:16 ERROR Executor: Exception in task 197.0 in stage 50.0 (TID 3236): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/02/temp_shuffle_facfe072-044f-44ff-8be2-bf8a7e511a7f (No such file or directory)\n",
      "24/05/01 00:22:16 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/20/temp_shuffle_ec036718-a2ce-4e25-893b-7c667f4dd2fb\n",
      "24/05/01 00:22:16 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 198.0 in stage 50.0 (TID 3237)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:16 ERROR Executor: Exception in task 198.0 in stage 50.0 (TID 3237): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/20/temp_shuffle_ec036718-a2ce-4e25-893b-7c667f4dd2fb (No such file or directory)\n",
      "24/05/01 00:22:16 WARN DiskBlockObjectWriter: Error deleting /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/39/temp_shuffle_0f99caf5-e365-4b06-9aec-fd24cc9ddafb\n",
      "24/05/01 00:22:16 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 199.0 in stage 50.0 (TID 3238)\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.blockManager()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$3(Task.scala:146)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:144)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/05/01 00:22:16 ERROR Executor: Exception in task 199.0 in stage 50.0 (TID 3238): /private/var/folders/gd/dnbt5zx96z3458pcdndk061c0000gn/T/blockmgr-4178c8a9-c145-4d09-a76f-41facc9b2cb2/39/temp_shuffle_0f99caf5-e365-4b06-9aec-fd24cc9ddafb (No such file or directory)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'spark' is your SparkSession object\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0dc5c3-0aad-49a3-b8a8-f8e96073bc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
